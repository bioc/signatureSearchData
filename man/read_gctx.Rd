% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_gctx.R
\name{read_gctx}
\alias{read_gctx}
\title{read large gctx file by chunks}
\usage{
read_gctx(gctx, cid, chunk = 5000)
}
\arguments{
\item{gctx}{path to the gctx file downloaded and decompressed from GEO}

\item{cid}{all the column ids to be read in}

\item{chunk}{number of columns read in at once}
}
\value{
DelayedMatrix object containing all the columns in 'cid' read from 'gctx'
}
\description{
Read in the matrix stored in gctx file by chunks and save it as hdf5 backed 
'DelayedArray'.
}
\details{
The large gctx file was read in by chunks. It avoids consuming all of the
memories by reading the full data at once. The chunk matrix was stored as
\code{\link[HDF5Array]{HDF5Array}}, which was realized by hdf5 backend. 
Then the chunks were
combined as a \code{\link[DelayedArray]{DelayedMatrix}} object that contains
 all the data read from gctx file
}
\examples{
a = 1
# lincs42_dlmat <- read_gctx(gctx="./data/GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx", 
# cid=meta42$sig_id))
}
\seealso{
\code{\link[DelayedArray]{DelayedMatrix}}, \code{\link[HDF5Array]{HDF5Array}}
}
